{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "# Pandarallelの準備\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "#PRED_FILES = [\"gcbert.pred\", \"codet5_old.pred\", \"codebert.pred\"]\n",
    "PRED_FILES = [\"gcbert.pred\", \"codet5.pred\", \"codebert.pred\"]\n",
    "DATA_DIR = \"./raw_data/\"\n",
    "COMMENT_FILE= \"data.comment\"\n",
    "SOURCE_FILE = \"data.source\"\n",
    "TARGET_FILE = \"data.target\"\n",
    "\n",
    "COMMENT_PATHS = f\"{DATA_DIR}{COMMENT_FILE}\"\n",
    "DATA_SOURCE_PATH = f\"{DATA_DIR}{SOURCE_FILE}\"\n",
    "DATA_TARGET_PATH = f\"{DATA_DIR}{TARGET_FILE}\"\n",
    "PRED_FULL_PATHS = [f\"{DATA_DIR}{f}\" for f in PRED_FILES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/3077703939.py:13: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs.to_excel(\"./data/data.xls\", index=False)\n"
     ]
    }
   ],
   "source": [
    "# read file per line and return dataframe and column name is filepath\n",
    "def read_file_per_line(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [l.rstrip() for l in lines]\n",
    "        return pd.DataFrame(lines, columns=[path.split(\"/\")[-1]])\n",
    "# read all files and combine them and return dataframe\n",
    "def read_files(paths):\n",
    "    dfs = [read_file_per_line(p) for p in paths]\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "dfs = read_files([DATA_SOURCE_PATH, DATA_TARGET_PATH, COMMENT_PATHS, *PRED_FULL_PATHS, ] )\n",
    "dfs.to_excel(\"./data/data.xls\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMScore of gcbert.pred is 0.10296684118673648\n",
      "EMScore of codet5.pred is 0.04712041884816754\n",
      "EMScore of codebert.pred is 0.09307737056428156\n"
     ]
    }
   ],
   "source": [
    "# add columns for is_correct between target and pred columns\n",
    "def add_is_correct_column(df, pred_col):\n",
    "    df[f\"is_correct_{pred_col}\"] = (df[TARGET_FILE] == df[pred_col])\n",
    "    print(f\"EMScore of {pred_col} is {df[f'is_correct_{pred_col}'].sum() / len(df)}\")\n",
    "    return df\n",
    "for pred_col in PRED_FILES:\n",
    "    \n",
    "    dfs = add_is_correct_column(dfs, pred_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMScore of gcbert.pred and codet5.pred is 0.33740546829552065\n",
      "EMScore of gcbert.pred and codebert.pred is 0.43339150668993603\n",
      "EMScore of codet5.pred and gcbert.pred is 0.33740546829552065\n",
      "EMScore of codet5.pred and codebert.pred is 0.3228621291448517\n",
      "EMScore of codebert.pred and gcbert.pred is 0.43339150668993603\n",
      "EMScore of codebert.pred and codet5.pred is 0.3228621291448517\n"
     ]
    }
   ],
   "source": [
    "# calc is_correct between each preds\n",
    "def add_is_correct_between_preds(df):\n",
    "    for pred_col in PRED_FILES:\n",
    "        for pred_col2 in PRED_FILES:\n",
    "            if pred_col == pred_col2:\n",
    "                continue\n",
    "            df[f\"em_{pred_col}_and_{pred_col2}\"] =  (df[pred_col] == df[pred_col2])\n",
    "            print(f\"EMScore of {pred_col} and {pred_col2} is {df[f'em_{pred_col}_and_{pred_col2}'].sum() / len(df)}\")\n",
    "    return df\n",
    "dfs = add_is_correct_between_preds(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all_correct:  35\n",
      "Sum of correct only gcbert: 73\n",
      "Sum of correct only codet5: 25\n",
      "Sum of correct only codebert: 51\n",
      "Sum of incorrect only gcbert: 13\n",
      "Sum of incorrect only codet5: 61\n",
      "Sum of incorrect only codebert: 8\n",
      "Sum of all_incorrect: 1453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:7: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"all_correct\"]].loc[:,[\"data.source\", \"data.target\", \"data.comment\"]].to_excel(\"./data/all_correct.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:10: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"is_correct_only_gcbert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\", \"codet5.pred\"]].to_excel(\"./data/is_correct_only_gcbert.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:13: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"is_correct_only_codet5\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\", \"gcbert.pred\"]].to_excel(\"./data/is_correct_only_codet5.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:16: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"is_correct_only_codebert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codet5.pred\", \"gcbert.pred\"]].to_excel(\"./data/is_correct_only_codebert.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:20: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"is_incorrect_only_gcbert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"gcbert.pred\"]].to_excel(\"./data/is_incorrect_only_gcbert.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:24: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"is_incorrect_only_codet5\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codet5.pred\"]].to_excel(\"./data/is_incorrect_only_codet5.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:28: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"is_incorrect_only_codebert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\"]].to_excel(\"./data/is_incorrect_only_codebert.xls\", index=False)\n",
      "/var/folders/c0/b2qqsnx935n275qlt_fqz8300000gn/T/ipykernel_33010/1222341432.py:33: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  dfs[dfs[\"all_incorrect\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\"]].to_excel(\"./data/all_incorrect.xls\", index=False)\n"
     ]
    }
   ],
   "source": [
    "# add columns of all_correct for all is_correct columns\n",
    "def add_all_correct_column(df):\n",
    "    df[\"all_correct\"] = df[[f\"is_correct_{pred_col}\" for pred_col in PRED_FILES]].all(axis=1)\n",
    "    print(\"Number of all_correct: \", df[\"all_correct\"].sum())\n",
    "    return df\n",
    "dfs = add_all_correct_column(dfs)\n",
    "dfs[dfs[\"all_correct\"]].loc[:,[\"data.source\", \"data.target\", \"data.comment\"]].to_excel(\"./data/all_correct.xls\", index=False)\n",
    "\n",
    "dfs[\"is_correct_only_gcbert\"] = dfs[\"is_correct_gcbert.pred\"] & ~dfs[\"is_correct_codet5.pred\"] & ~dfs[\"is_correct_codebert.pred\"]\n",
    "dfs[dfs[\"is_correct_only_gcbert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\", \"codet5.pred\"]].to_excel(\"./data/is_correct_only_gcbert.xls\", index=False)\n",
    "print(\"Sum of correct only gcbert: \" + str(sum(dfs[\"is_correct_only_gcbert\"])))\n",
    "dfs[\"is_correct_only_codet5\"] = dfs[\"is_correct_codet5.pred\"] & ~dfs[\"is_correct_gcbert.pred\"] & ~dfs[\"is_correct_codebert.pred\"]\n",
    "dfs[dfs[\"is_correct_only_codet5\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\", \"gcbert.pred\"]].to_excel(\"./data/is_correct_only_codet5.xls\", index=False)\n",
    "print(\"Sum of correct only codet5: \" + str(sum(dfs[\"is_correct_only_codet5\"])))\n",
    "dfs[\"is_correct_only_codebert\"] = dfs[\"is_correct_codebert.pred\"] & ~dfs[\"is_correct_codet5.pred\"] & ~dfs[\"is_correct_gcbert.pred\"]\n",
    "dfs[dfs[\"is_correct_only_codebert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codet5.pred\", \"gcbert.pred\"]].to_excel(\"./data/is_correct_only_codebert.xls\", index=False)\n",
    "print(\"Sum of correct only codebert: \" + str(sum(dfs[\"is_correct_only_codebert\"])))\n",
    "\n",
    "dfs[\"is_incorrect_only_gcbert\"] = ~dfs[\"is_correct_gcbert.pred\"] & dfs[\"is_correct_codet5.pred\"] & dfs[\"is_correct_codebert.pred\"]\n",
    "dfs[dfs[\"is_incorrect_only_gcbert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"gcbert.pred\"]].to_excel(\"./data/is_incorrect_only_gcbert.xls\", index=False)\n",
    "print(\"Sum of incorrect only gcbert: \" + str(sum(dfs[\"is_incorrect_only_gcbert\"])))\n",
    "\n",
    "dfs[\"is_incorrect_only_codet5\"] = dfs[\"is_correct_gcbert.pred\"] & ~dfs[\"is_correct_codet5.pred\"] & dfs[\"is_correct_codebert.pred\"]\n",
    "dfs[dfs[\"is_incorrect_only_codet5\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codet5.pred\"]].to_excel(\"./data/is_incorrect_only_codet5.xls\", index=False)\n",
    "print(\"Sum of incorrect only codet5: \" + str(sum(dfs[\"is_incorrect_only_codet5\"])))\n",
    "\n",
    "dfs[\"is_incorrect_only_codebert\"] = dfs[\"is_correct_gcbert.pred\"] & dfs[\"is_correct_codet5.pred\"] & ~dfs[\"is_correct_codebert.pred\"]\n",
    "dfs[dfs[\"is_incorrect_only_codebert\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\"]].to_excel(\"./data/is_incorrect_only_codebert.xls\", index=False)\n",
    "print(\"Sum of incorrect only codebert: \" + str(sum(dfs[\"is_incorrect_only_codebert\"])))\n",
    "\n",
    "\n",
    "dfs[\"all_incorrect\"] = ~dfs[\"is_correct_gcbert.pred\"] & ~dfs[\"is_correct_codet5.pred\"] & ~dfs[\"is_correct_codebert.pred\"]\n",
    "dfs[dfs[\"all_incorrect\"] ].loc[:,[\"data.source\", \"data.target\", \"data.comment\", \"codebert.pred\"]].to_excel(\"./data/all_incorrect.xls\", index=False)\n",
    "print(\"Sum of all_incorrect: \" + str(sum(dfs[\"all_incorrect\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bleu4_gcbert.pred:0.7503426944875469\n",
      "Average bleu4_codet5.pred:0.755592552249078\n",
      "Average bleu4_codebert.pred:0.748118504192774\n"
     ]
    }
   ],
   "source": [
    "# calc bleu score\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "def calc_bleu4(pred:str, tgt:str) -> float:\n",
    "    fn = SmoothingFunction().method1\n",
    "    return sentence_bleu([tgt.split()], pred.split())\n",
    "\n",
    "# calc bles score between preds and target\n",
    "def calc_bleu4_between_preds_and_target(df):\n",
    "    for pred_col in PRED_FILES:\n",
    "        df[f\"bleu4_{pred_col}\"] = df.apply(lambda x: calc_bleu4(x[pred_col], x[TARGET_FILE]), axis=1)\n",
    "        print(f\"Average bleu4_{pred_col}:{np.average(df[f'bleu4_{pred_col}'])}\")\n",
    "    return df\n",
    "\n",
    "dfs = calc_bleu4_between_preds_and_target(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bleu4_gcbert.pred_and_codet5.pred:0.8398327863187209\n",
      "Average bleu4_gcbert.pred_and_codebert.pred:0.8689556180856352\n",
      "Average bleu4_codet5.pred_and_gcbert.pred:0.8436324670445154\n",
      "Average bleu4_codet5.pred_and_codebert.pred:0.8432105093066808\n",
      "Average bleu4_codebert.pred_and_gcbert.pred:0.8708210022627797\n",
      "Average bleu4_codebert.pred_and_codet5.pred:0.8413426594119572\n"
     ]
    }
   ],
   "source": [
    "# calc bleu4 between each preds\n",
    "def calc_bleu4_between_preds(df):\n",
    "    for pred_col in PRED_FILES:\n",
    "        for pred_col2 in PRED_FILES:\n",
    "            if pred_col == pred_col2:\n",
    "                continue\n",
    "            df[f\"bleu4_{pred_col}_and_{pred_col2}\"] = df.apply(lambda x: calc_bleu4(x[pred_col], x[pred_col2]), axis=1)\n",
    "            print(f\"Average bleu4_{pred_col}_and_{pred_col2}:{np.average(df[f'bleu4_{pred_col}_and_{pred_col2}'])}\")\n",
    "    return df\n",
    "dfs = calc_bleu4_between_preds(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['gcbert.pred', 'data.target'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mセル9 を /Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAverage levenshtein_\u001b[39m\u001b[39m{\u001b[39;00mpred_col\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39maverage(df[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevenshtein_\u001b[39m\u001b[39m{\u001b[39;00mpred_col\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dfs \u001b[39m=\u001b[39m calc_levenshtein_between_preds_and_target(dfs)\n",
      "\u001b[1;32mセル9 を /Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb\u001b[0m in \u001b[0;36mcalc_levenshtein_between_preds_and_target\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_levenshtein_between_preds_and_target\u001b[39m(df):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pred_col \u001b[39min\u001b[39;00m PRED_FILES:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         df[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlevenshtein_\u001b[39m\u001b[39m{\u001b[39;00mpred_col\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mloc[[pred_col, TARGET_FILE]]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: textdistance\u001b[39m.\u001b[39mlevenshtein\u001b[39m.\u001b[39mnormalized_similarity(x[pred_col], x[TARGET_FILE]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAverage levenshtein_\u001b[39m\u001b[39m{\u001b[39;00mpred_col\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39maverage(df[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevenshtein_\u001b[39m\u001b[39m{\u001b[39;00mpred_col\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/akihito/Desktop/research/ResultAnalysis/resultAnalysis.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/code2seq_pytorch-8rO2Scl4/lib/python3.8/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/code2seq_pytorch-8rO2Scl4/lib/python3.8/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1189\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1193\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/code2seq_pytorch-8rO2Scl4/lib/python3.8/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/code2seq_pytorch-8rO2Scl4/lib/python3.8/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1324\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1325\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1327\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1329\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/code2seq_pytorch-8rO2Scl4/lib/python3.8/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/code2seq_pytorch-8rO2Scl4/lib/python3.8/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['gcbert.pred', 'data.target'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "# calc Levenshtein distance between preds and target\n",
    "def calc_levenshtein_between_preds_and_target(df):\n",
    "    for pred_col in PRED_FILES:\n",
    "        df[f\"levenshtein_{pred_col}\"] = df.loc[:,[pred_col, TARGET_FILE]].apply(lambda x: textdistance.levenshtein.normalized_similarity(x[pred_col], x[TARGET_FILE]), axis=1)\n",
    "        print(f\"Average levenshtein_{pred_col}:{np.average(df[f'levenshtein_{pred_col}'])}\")\n",
    "    return df\n",
    "dfs = calc_levenshtein_between_preds_and_target(dfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average levenshtein_gcbert.pred_and_codet5.pred:0.8828459633624532\n",
      "Average levenshtein_gcbert.pred_and_codebert.pred:0.9022055387884687\n",
      "Average levenshtein_codet5.pred_and_gcbert.pred:0.8828459633624532\n",
      "Average levenshtein_codet5.pred_and_codebert.pred:0.8813396701129622\n",
      "Average levenshtein_codebert.pred_and_gcbert.pred:0.9022055387884687\n",
      "Average levenshtein_codebert.pred_and_codet5.pred:0.8813396701129622\n"
     ]
    }
   ],
   "source": [
    "# calc Levenshtein distance between each preds\n",
    "def calc_levenshtein_between_preds(df):\n",
    "    for pred_col in PRED_FILES:\n",
    "        for pred_col2 in PRED_FILES:\n",
    "            if pred_col == pred_col2:\n",
    "                continue\n",
    "            df[f\"levenshtein_{pred_col}_and_{pred_col2}\"] = df.loc[:, [pred_col,pred_col2]].apply(lambda x: textdistance.levenshtein.normalized_similarity(x[pred_col], x[pred_col2]), axis=1)\n",
    "            print(f\"Average levenshtein_{pred_col}_and_{pred_col2}:{np.average(df[f'levenshtein_{pred_col}_and_{pred_col2}'])}\")\n",
    "    return df\n",
    "dfs = calc_levenshtein_between_preds(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1719 entries, 0 to 1718\n",
      "Data columns (total 22 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   data.source                          1719 non-null   object \n",
      " 1   data.target                          1719 non-null   object \n",
      " 2   data.comment                         1719 non-null   object \n",
      " 3   gcbert.pred                          1719 non-null   object \n",
      " 4   codet5.pred                          1719 non-null   object \n",
      " 5   codebert.pred                        1719 non-null   object \n",
      " 6   is_correct_gcbert.pred               1719 non-null   bool   \n",
      " 7   is_correct_codet5.pred               1719 non-null   bool   \n",
      " 8   is_correct_codebert.pred             1719 non-null   bool   \n",
      " 9   all_correct                          1719 non-null   bool   \n",
      " 10  is_correct_only_gcbert               1719 non-null   bool   \n",
      " 11  is_correct_only_codet5               1719 non-null   bool   \n",
      " 12  is_correct_only_codebert             1719 non-null   bool   \n",
      " 13  bleu4_gcbert.pred                    1719 non-null   float64\n",
      " 14  bleu4_codet5.pred                    1719 non-null   float64\n",
      " 15  bleu4_codebert.pred                  1719 non-null   float64\n",
      " 16  bleu4_gcbert.pred_and_codet5.pred    1719 non-null   float64\n",
      " 17  bleu4_gcbert.pred_and_codebert.pred  1719 non-null   float64\n",
      " 18  bleu4_codet5.pred_and_gcbert.pred    1719 non-null   float64\n",
      " 19  bleu4_codet5.pred_and_codebert.pred  1719 non-null   float64\n",
      " 20  bleu4_codebert.pred_and_gcbert.pred  1719 non-null   float64\n",
      " 21  bleu4_codebert.pred_and_codet5.pred  1719 non-null   float64\n",
      "dtypes: bool(7), float64(9), object(6)\n",
      "memory usage: 213.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code2seq_pytorch-8rO2Scl4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a126fdec72c602ed1945f08a52748dd7e00d0d37dca84bb060ede0990d2fb6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
